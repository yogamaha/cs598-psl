{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aOzLITIUV5Dd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T41ehHPNXUgu",
    "outputId": "ab6c1ac9-3557-4df3-d1a5-54b3541a9bb6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "file_path = 'faithful.dat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJFEBqGtXfED",
    "outputId": "fb33f602-8ba2-41f7-e929-a93078b63758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      eruptions  waiting\n",
       "1        3.600       79\n",
       "2        1.800       54\n",
       "3        3.333       74\n",
       "4        2.283       62\n",
       "5        4.533       85\n",
       "..         ...      ...\n",
       "268      4.117       81\n",
       "269      2.150       46\n",
       "270      4.417       90\n",
       "271      1.817       46\n",
       "272      4.467       74\n",
       "\n",
       "[272 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(file_path, sep=\"\\s+\", index_col=0)\n",
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qjdS42s47c1p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def E_step(X, means, covariance, prob):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the responsibilities of each data point for each component.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input data (n x d)\n",
    "    - means: Matrix of means for each component (d x G).\n",
    "    - covariance: Shared covariance matrix (d x d).\n",
    "    - prob: A G-dimensional probability vector (p1,…,pG)\n",
    "\n",
    "    Returns:\n",
    "    - gamma: An n x G matrix where each (i, j) entry represents P(Zi=k | xi).\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    G = len(prob)\n",
    "\n",
    "    gamma = np.zeros((n, G))\n",
    "\n",
    "\n",
    "    for k in range(G):\n",
    "        mean_k = means[:, k]\n",
    "        prob_k = prob[k]\n",
    "\n",
    "        datanp = data.to_numpy()[:, np.newaxis] # add a new first dimension to x\n",
    "        diff = datanp - mean_k.T\n",
    "        inv_cov = np.linalg.inv(covariance)\n",
    "\n",
    "        prefactor = (2*np.pi)**-(d/2)*np.linalg.det(inv_cov)\n",
    "        exp_term = np.exp(-np.einsum('ijk, kl, ijl->ij', diff, inv_cov, diff) / 2)\n",
    "\n",
    "        gamma_k = prefactor * exp_term\n",
    "        gamma_k = gamma_k * prob_k\n",
    "\n",
    "        gamma[:, k] = gamma_k.ravel()\n",
    "\n",
    "    # Normalize the responsibilities so that they sum to 1 for each data point\n",
    "    gamma = gamma / np.sum(gamma, axis=1, keepdims=True)\n",
    "\n",
    "    return gamma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XoX5uA2rcOLD"
   },
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "\n",
    "    n, d = X.shape\n",
    "    n, G = gamma.shape\n",
    "\n",
    "    # Update mean\n",
    "    gamma_sum = np.sum(gamma,axis=0) #1 x G\n",
    "    updated_mean = np.dot(gamma.T, data)/gamma_sum.T[:, np.newaxis] #G x d\n",
    "\n",
    "    updated_mean_t = updated_mean.T #d x G\n",
    "\n",
    "    # Update probs for component k\n",
    "    updated_probs = gamma_sum/n\n",
    "\n",
    "    # Update covariance for component k\n",
    "    shared_covariance = np.zeros((d, d))\n",
    "\n",
    "    for k in range(G):\n",
    "        diff_k = data - updated_mean[k][np.newaxis,:]\n",
    "        weighted_covariance = np.dot(diff_k.T, (gamma[:, k][:, np.newaxis] * diff_k))\n",
    "\n",
    "        shared_covariance += weighted_covariance\n",
    "\n",
    "    total_responsibilities = np.sum(gamma, axis=0)\n",
    "    shared_covariance /= np.sum(total_responsibilities)\n",
    "\n",
    "    return updated_mean_t, shared_covariance, updated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MqCb-k4bc2ki"
   },
   "outputs": [],
   "source": [
    "def log_likelihood(X, means, covariance, prob):\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data given the parameters of GMM\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input data (n x d)\n",
    "    - means: Matrix of means for each component (d x G).\n",
    "    - covariance: Shared covariance matrix (d x d).\n",
    "    - prob: A G-dimensional probability vector (p1,…,pG)\n",
    "\n",
    "    Returns:\n",
    "    - log_lik: The log-likelihood of the data given the model parameters.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    G = len(prob)\n",
    "\n",
    "    likelihood = np.zeros((n, G))\n",
    "\n",
    "\n",
    "    for k in range(G):\n",
    "        mean_k = means[:, k]\n",
    "        prob_k = prob[k]\n",
    "\n",
    "        datanp = data.to_numpy()[:, np.newaxis] # add a new first dimension to x\n",
    "        diff = datanp - mean_k.T\n",
    "        inv_cov = np.linalg.inv(covariance)\n",
    "\n",
    "        prefactor = (2*np.pi)**-(d/2)*np.linalg.det(inv_cov)\n",
    "        exp_term = np.exp(-np.einsum('ijk, kl, ijl->ij', diff, inv_cov, diff) / 2)\n",
    "\n",
    "        pdf_k = prefactor * exp_term\n",
    "        multi_pdf_k = pdf_k * prob_k\n",
    "\n",
    "        likelihood[:, k] = multi_pdf_k.ravel()\n",
    "\n",
    "    likelihood_G = np.sum(likelihood, axis=1, keepdims=True)\n",
    "\n",
    "    log_lik = np.sum(np.log(likelihood_G))\n",
    "\n",
    "    return log_lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_fn(X, G, prob, mean, sigma):\n",
    "    p = np.zeros([G, X.shape[0]])\n",
    "    \n",
    "    eq1 = prob[:, np.newaxis]\n",
    "    \n",
    "    sigma_det = np.linalg.det(sigma)\n",
    "    \n",
    "    A = X.T\n",
    "    A_minus_mean = (A[np.newaxis, :, :] - mean[:, :, np.newaxis])\n",
    "    eq3 = (np.linalg.inv(sigma) @ A_minus_mean) * A_minus_mean\n",
    "    eq3 = -0.5 * np.sum(eq3, axis=1)\n",
    "    eq3 = np.exp(eq3) / (2 * np.pi * np.sqrt(sigma_det))\n",
    "    \n",
    "    p = eq1 * eq3\n",
    "    \n",
    "    loglik_val = np.sum(np.log(np.sum(p, axis=0)))\n",
    "    \n",
    "    return loglik_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m2OFcxIIFUwV"
   },
   "outputs": [],
   "source": [
    "def test_log_likelihood(X, means, covariances, mixing_coefficients):\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data given the parameters of a Gaussian Mixture Model (GMM).\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input data (n x d), where n is the number of data points and d is the dimensionality.\n",
    "    - means: List of means for each component (G x d).\n",
    "    - covariances: List of covariance matrices for each component (G x d x d).\n",
    "    - mixing_coefficients: List of mixing coefficients for each component (G).\n",
    "\n",
    "    Returns:\n",
    "    - log_lik: The log-likelihood of the data given the model parameters.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    G = len(means)\n",
    "\n",
    "    log_lik = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        data_point = X.to_numpy()[i, :]\n",
    "        likelihood_i = 0\n",
    "\n",
    "        for k in range(G):\n",
    "            mean_k = means[k]\n",
    "            covariance_k = covariances[k]\n",
    "            mixing_coefficient_k = mixing_coefficients[k]\n",
    "\n",
    "            # Calculate the likelihood of the data point for component k\n",
    "            diff = data_point - mean_k\n",
    "            exponent = -0.5 * np.dot(np.dot(diff, np.linalg.inv(covariance_k)), diff)\n",
    "            likelihood_k = mixing_coefficient_k * (1.0 / np.sqrt((2 * np.pi) ** d * np.linalg.det(covariance_k))) * np.exp(exponent)\n",
    "            likelihood_i += likelihood_k\n",
    "\n",
    "        log_lik += np.log(likelihood_i)\n",
    "\n",
    "    return log_lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "B1mDZkD9F8UF"
   },
   "outputs": [],
   "source": [
    "def myEM(data, G,means, covariance, prob):\n",
    "\n",
    "    n, p = data.shape\n",
    "\n",
    "    update_means = means\n",
    "    update_covariance = covariance\n",
    "    update_prob = prob\n",
    "\n",
    "\n",
    "    for iteration in range(1):\n",
    "\n",
    "        # E-step: Calculate gamma\n",
    "        gamma = E_step(data, update_means, update_covariance, update_prob)\n",
    "        #print(f\"gamma={gamma}\")\n",
    "\n",
    "        # M-step: Update parameters\n",
    "        M_means, M_covariance, M_prob = M_step(data, gamma)\n",
    "\n",
    "        update_means = M_means\n",
    "        update_covariance = M_covariance\n",
    "        update_prob = M_prob\n",
    "\n",
    "        print (\"update_prob: \",update_prob)\n",
    "        print (\"update_means: \",update_means)\n",
    "        print (\"update_covariance: \",update_covariance)\n",
    "\n",
    "    # Calculate the log-likelihood\n",
    "    loglik = log_likelihood(data, update_means, update_covariance, update_prob)\n",
    "    #loglik = loglik_fn(data, G, update_prob, update_means, update_covariance)\n",
    "\n",
    "    return update_means, update_covariance, update_prob,loglik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "irGB1hGTHh-S"
   },
   "outputs": [],
   "source": [
    "def testing(data,G):\n",
    "\n",
    "    n, p = data.shape\n",
    "\n",
    "    if G==2:\n",
    "      # Set initial values\n",
    "      p1 = 10 / n\n",
    "      p2 = 1 - p1\n",
    "      initial_means = np.array([data[:10].mean(axis=0), data[10:].mean(axis=0)]).T\n",
    "      diff1 = data[:10] - initial_means[:, 0]\n",
    "      diff2 = data[10:] - initial_means[:, 1]\n",
    "      initial_covariance = (1 / n) * (np.dot(diff1.T, diff1) + np.dot(diff2.T, diff2))\n",
    "\n",
    "      initial_mixing_coefficients = np.array([p1, p2])\n",
    "\n",
    "    if G == 3:\n",
    "      # Set initial values\n",
    "      p1 = 10 / n\n",
    "      p2 = 20 / n\n",
    "      p3 = 1 - p1 - p2\n",
    "      initial_means = np.array([data[:10].mean(axis=0), data[10:30].mean(axis=0), data[30:].mean(axis=0)]).T\n",
    "      print (initial_means)\n",
    "\n",
    "      diff1 = data[:10] - initial_means[:, 0]\n",
    "      diff2 = data[10:30] - initial_means[:, 1]\n",
    "      diff3 = data[30:] - initial_means[:, 2]\n",
    "\n",
    "      initial_covariance = (1 / n) * (np.dot(diff1.T, diff1) + np.dot(diff2.T, diff2) + np.dot(diff3.T, diff3))\n",
    "\n",
    "      initial_mixing_coefficients = np.array([p1, p2, p3])\n",
    "\n",
    "\n",
    "    # Perform the EM algorithm\n",
    "    print(f\"data={data}\")\n",
    "    print(f\"G={G}\")\n",
    "    print(f\"initial_means={initial_means}\")\n",
    "    print(f\"initial_covariance={initial_covariance}\")\n",
    "    print(f\"initial_mixing_coefficients={initial_mixing_coefficients}\")\n",
    "    mean, covariance, probs,loglik = myEM(data,G, initial_means, initial_covariance, initial_mixing_coefficients)\n",
    "\n",
    "    print (\"prob: \",probs)\n",
    "    print (\"mean: \",mean)\n",
    "    print (\"Sigma: \",covariance)\n",
    "    print (\"loglik: \", loglik)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71UU52xfMg2O",
    "outputId": "22280fa9-301b-4fe5-fbb4-25212f42c167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=     eruptions  waiting\n",
      "1        3.600       79\n",
      "2        1.800       54\n",
      "3        3.333       74\n",
      "4        2.283       62\n",
      "5        4.533       85\n",
      "..         ...      ...\n",
      "268      4.117       81\n",
      "269      2.150       46\n",
      "270      4.417       90\n",
      "271      1.817       46\n",
      "272      4.467       74\n",
      "\n",
      "[272 rows x 2 columns]\n",
      "G=2\n",
      "initial_means=[[ 3.3032      3.49482824]\n",
      " [71.8        70.86259542]]\n",
      "initial_covariance=[[  1.29663847  13.93278021]\n",
      " [ 13.93278021 184.11269645]]\n",
      "initial_mixing_coefficients=[0.03676471 0.96323529]\n",
      "update_prob:  [0.03685524 0.96314476]\n",
      "update_means:  [[ 3.31211483  3.49450513]\n",
      " [71.98706055 70.85534934]]\n",
      "update_covariance:  [[  1.29675804  13.93374588]\n",
      " [ 13.93374588 184.09835147]]\n",
      "prob:  [0.03685524 0.96314476]\n",
      "mean:  [[ 3.31211483  3.49450513]\n",
      " [71.98706055 70.85534934]]\n",
      "Sigma:  [[  1.29675804  13.93374588]\n",
      " [ 13.93374588 184.09835147]]\n",
      "loglik:  -1806.2020728567454\n"
     ]
    }
   ],
   "source": [
    "testing(data,G=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.3032      3.175       3.52126033]\n",
      " [71.8        68.25       71.0785124 ]]\n",
      "data=     eruptions  waiting\n",
      "1        3.600       79\n",
      "2        1.800       54\n",
      "3        3.333       74\n",
      "4        2.283       62\n",
      "5        4.533       85\n",
      "..         ...      ...\n",
      "268      4.117       81\n",
      "269      2.150       46\n",
      "270      4.417       90\n",
      "271      1.817       46\n",
      "272      4.467       74\n",
      "\n",
      "[272 rows x 2 columns]\n",
      "G=3\n",
      "initial_means=[[ 3.3032      3.175       3.52126033]\n",
      " [71.8        68.25       71.0785124 ]]\n",
      "initial_covariance=[[  1.28849554  13.8662627 ]\n",
      " [ 13.8662627  183.56933185]]\n",
      "initial_mixing_coefficients=[0.03676471 0.07352941 0.88970588]\n",
      "prob:  [0.04363422 0.07718656 0.87917922]\n",
      "mean:  [[ 3.51006918  2.81616674  3.54564083]\n",
      " [77.10563811 63.35752634 71.25084801]]\n",
      "Sigma:  [[  1.26015772  13.51153756]\n",
      " [ 13.51153756 177.96419105]]\n",
      "loglik:  -1796.7033598743544\n"
     ]
    }
   ],
   "source": [
    "testing(data,G=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
