{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LHSkMLcpmZjO"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3umiJ1R1GlJ"
   },
   "source": [
    "Questions:\n",
    "1. For Winsorazation, why professor only suggested 95% percentile upper bound, but not 5% percentile lower bound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mA7LD8jKnC9R"
   },
   "outputs": [],
   "source": [
    "def linear_trainset_preprocessing(df):\n",
    "\n",
    "\n",
    "    x_train = df.drop(columns=['PID','Longitude','Latitude','Sale_Price'], axis = 1)\n",
    "    y_train = np.log(df[\"Sale_Price\"])\n",
    "\n",
    "\n",
    "    #Only \"Garage_Yr_Blt\" has missing values upon examination, replace the missing values with zero.\n",
    "    x_train.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # To deal with inbalance issue, remove the variables that has one value dominates with a high percentage greater than 98%.\n",
    "    variables_to_remove = []\n",
    "    for column in x_train:\n",
    "      dominant_percentage = x_train[column].value_counts(normalize=True).max()\n",
    "      if dominant_percentage > 0.98:\n",
    "        variables_to_remove.append(column)\n",
    "\n",
    "    x_train = x_train.drop(columns=variables_to_remove)\n",
    "\n",
    "    # Calculate medians for numerical columns and use those medians to fill missing values in the test set.\n",
    "    \"\"\"\n",
    "    numerical_columns = x_train[['Lot_Frontage', 'Lot_Area', 'Year_Built', 'Year_Remod_Add',\n",
    "       'Mas_Vnr_Area', 'BsmtFin_SF_1', 'BsmtFin_SF_2', 'Bsmt_Unf_SF',\n",
    "       'Total_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Low_Qual_Fin_SF',\n",
    "       'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath',\n",
    "       'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd',\n",
    "       'Fireplaces', 'Garage_Yr_Blt', 'Garage_Cars', 'Garage_Area',\n",
    "       'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch',\n",
    "       'Screen_Porch', 'Pool_Area', 'Misc_Val', 'Mo_Sold', 'Year_Sold']]  \n",
    "    \"\"\"\n",
    "    numerical_columns = x_train.select_dtypes(include=np.number)\n",
    "    medians_dict = numerical_columns.median().to_dict()\n",
    "\n",
    "\n",
    "    # For outliers in numerical variables, use winsorization to replace the highest 5% of the data by the value of the data at the 95th percentile\n",
    "    #store the max values for winsorized columns and use it to clip the test data later.\n",
    "\n",
    "    numerical_columns = ['Lot_Frontage', 'Lot_Area', 'Year_Built', 'Year_Remod_Add',\n",
    "       'Mas_Vnr_Area', 'BsmtFin_SF_1', 'BsmtFin_SF_2', 'Bsmt_Unf_SF',\n",
    "       'Total_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Low_Qual_Fin_SF',\n",
    "       'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath',\n",
    "       'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd',\n",
    "       'Fireplaces', 'Garage_Yr_Blt', 'Garage_Cars', 'Garage_Area',\n",
    "       'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch',\n",
    "       'Screen_Porch', 'Pool_Area', 'Misc_Val', 'Mo_Sold', 'Year_Sold']\n",
    "    numerical_columns = x_train.select_dtypes(include=['number']).columns.tolist()\n",
    "    winsorized_max = {}\n",
    "\n",
    "    for column in numerical_columns:\n",
    "        x_train[column] = winsorize(x_train[column], limits=(0, 0.05))\n",
    "        winsorized_max[column] = x_train[column].max()\n",
    "\n",
    "\n",
    "    # Encode catogorical variables to create binary dummy variables\n",
    "    columns_to_encode = ['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape',\n",
    "       'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood',\n",
    "       'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style',\n",
    "       'Overall_Qual', 'Overall_Cond', 'Roof_Style', 'Roof_Matl',\n",
    "       'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Qual',\n",
    "       'Exter_Cond', 'Foundation', 'Bsmt_Qual', 'Bsmt_Cond', 'Bsmt_Exposure',\n",
    "       'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC',\n",
    "       'Central_Air', 'Electrical', 'Kitchen_Qual', 'Functional',\n",
    "       'Fireplace_Qu', 'Garage_Type', 'Garage_Finish', 'Garage_Qual',\n",
    "       'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Misc_Feature',\n",
    "       'Sale_Type', 'Sale_Condition']\n",
    "    columns_to_encode = x_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    encoder = OneHotEncoder(sparse_output=False,handle_unknown = \"ignore\")\n",
    "    encoder.fit(x_train[columns_to_encode])\n",
    "\n",
    "    x_train_encoded_data = encoder.transform(x_train[columns_to_encode])\n",
    "    x_train_encoded_df = pd.DataFrame(x_train_encoded_data, columns=encoder.get_feature_names_out(input_features=columns_to_encode))\n",
    "    x_train_all = pd.concat([x_train_encoded_df, x_train.drop(columns=columns_to_encode)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a StandardScaler instance and fit it on the training data,\n",
    "    # Transform the training data using the fitted scaler and transform the test data using the same scaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train_all)\n",
    "    X_train_final = scaler.transform(x_train_all)\n",
    "\n",
    "    return X_train_final, y_train, variables_to_remove, medians_dict, winsorized_max,encoder, columns_to_encode, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QOKRLhnuigXW"
   },
   "outputs": [],
   "source": [
    "def linear_testset_preprocessing(df,variables_to_remove,medians_dict, winsorized_max, encoder, columns_to_encode, scaler):\n",
    "\n",
    "\n",
    "    x_test = df.drop(columns=['PID','Longitude','Latitude'], axis = 1)\n",
    "    x_test_PID = df[\"PID\"]\n",
    "\n",
    "    x_test = x_test.drop(columns=variables_to_remove)\n",
    "\n",
    "    # Fill missing values in the test set using the stored medians\n",
    "    for col, median in medians_dict.items():\n",
    "        x_test[col].fillna(median, inplace=True)\n",
    "\n",
    "    # Apply Winsorization to specified columns using bounds from train data\n",
    "    for column, max in winsorized_max.items():\n",
    "      x_test[column] = np.clip(x_test[column], 0, max)\n",
    "\n",
    "\n",
    "    # Transform the test data using the same encoder of train data\n",
    "    x_test_encoded = encoder.transform(x_test[columns_to_encode])\n",
    "    x_test_encoded_df = pd.DataFrame(x_test_encoded, columns=encoder.get_feature_names_out(input_features=columns_to_encode))\n",
    "    x_test_encoded_all = pd.concat([x_test_encoded_df, x_test.drop(columns=columns_to_encode)], axis=1)\n",
    "\n",
    "\n",
    "    X_test_final = scaler.transform(x_test_encoded_all)\n",
    "\n",
    "\n",
    "    return X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hMK9eE3-U1Wa"
   },
   "outputs": [],
   "source": [
    "def tree_trainset_preprocessing(df):\n",
    "\n",
    "      x_train = df.drop(columns=['PID','Sale_Price'], axis = 1)\n",
    "      y_train = np.log(df[\"Sale_Price\"])\n",
    "\n",
    "\n",
    "      #Only \"Garage_Yr_Blt\" has missing values upon examination, replace the missing values with zero.\n",
    "      x_train.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "      # Calculate medians for numerical columns and use those medians to fill missing values in the test set.\n",
    "      numerical_columns = ['Lot_Frontage', 'Lot_Area', 'Year_Built', 'Year_Remod_Add', 'Mas_Vnr_Area', \n",
    "                           'BsmtFin_SF_1', 'BsmtFin_SF_2', 'Bsmt_Unf_SF',\n",
    "                           'Total_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Low_Qual_Fin_SF',\n",
    "                           'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath',\n",
    "                           'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd',\n",
    "                           'Fireplaces', 'Garage_Yr_Blt', 'Garage_Cars', 'Garage_Area',\n",
    "                           'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch',\n",
    "                           'Screen_Porch', 'Pool_Area', 'Misc_Val', 'Mo_Sold', 'Year_Sold']    \n",
    "      numerical_columns = x_train.select_dtypes(include=np.number)\n",
    "      medians_dict = numerical_columns.median().to_dict()\n",
    "\n",
    "\n",
    "      # Encode catogorical variables to create binary dummy variables\n",
    "      columns_to_encode = ['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape',\n",
    "        'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood',\n",
    "        'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style',\n",
    "        'Overall_Qual', 'Overall_Cond', 'Roof_Style', 'Roof_Matl',\n",
    "        'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Qual',\n",
    "        'Exter_Cond', 'Foundation', 'Bsmt_Qual', 'Bsmt_Cond', 'Bsmt_Exposure',\n",
    "        'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC',\n",
    "        'Central_Air', 'Electrical', 'Kitchen_Qual', 'Functional',\n",
    "        'Fireplace_Qu', 'Garage_Type', 'Garage_Finish', 'Garage_Qual',\n",
    "        'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Misc_Feature',\n",
    "        'Sale_Type', 'Sale_Condition']\n",
    "    \n",
    "      columns_to_encode = x_train.select_dtypes(include=['object']).columns.tolist()\n",
    "      encoder = OneHotEncoder(sparse_output=False,handle_unknown = \"ignore\")\n",
    "      encoder.fit(x_train[columns_to_encode])\n",
    "\n",
    "      x_train_encoded_data = encoder.transform(x_train[columns_to_encode])\n",
    "      x_train_encoded_df = pd.DataFrame(x_train_encoded_data, columns=encoder.get_feature_names_out(input_features=columns_to_encode))\n",
    "      x_train_all = pd.concat([x_train_encoded_df, x_train.drop(columns=columns_to_encode)], axis=1)\n",
    "\n",
    "\n",
    "      return x_train_all, y_train, medians_dict,encoder, columns_to_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tliGlLIgXoRr"
   },
   "outputs": [],
   "source": [
    "def tree_testset_preprocessing(df,medians_dict, encoder, columns_to_encode):\n",
    "\n",
    "\n",
    "    x_test = df.drop(columns=['PID'], axis = 1)\n",
    "    x_test_PID = df[\"PID\"]\n",
    "\n",
    "    # Fill missing values in the test set using the stored medians\n",
    "    for col, median in medians_dict.items():\n",
    "        x_test[col].fillna(median, inplace=True)\n",
    "\n",
    "\n",
    "    # Transform the test data using the same encoder of train data\n",
    "    x_test_encoded = encoder.transform(x_test[columns_to_encode])\n",
    "    x_test_encoded_df = pd.DataFrame(x_test_encoded, columns=encoder.get_feature_names_out(input_features=columns_to_encode))\n",
    "    X_test_final = pd.concat([x_test_encoded_df, x_test.drop(columns=columns_to_encode)], axis=1)\n",
    "\n",
    "    return X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d1g5HXRTmEFL"
   },
   "outputs": [],
   "source": [
    "def lasso(X_train,X_test,Y_train,Y_test):\n",
    "\n",
    "    lasso_alphas = np.logspace(-10, 10, 100)\n",
    "    lassocv = LassoCV(alphas = lasso_alphas, cv = 10)\n",
    "    lassocv.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    cv_alpha = lassocv.alpha_\n",
    "    print(\"lasso:cv_alpha=\", cv_alpha )\n",
    "\n",
    "    #### alpha_min\n",
    "    lasso_model_min = Lasso(alpha = cv_alpha, max_iter=5000)\n",
    "    lasso_model_min.fit(X_train, Y_train)\n",
    "    lasso_rmse = mean_squared_error(Y_test, lasso_model_min.predict(X_test))\n",
    "\n",
    "    return sqrt(lasso_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(X_train,X_test,Y_train,Y_test):\n",
    "\n",
    "    alphas = np.logspace(-10, 10, 100)\n",
    "    ridgecv = RidgeCV(alphas = alphas, cv = 10)\n",
    "    ridgecv.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    cv_alpha = ridgecv.alpha_\n",
    "    print(\"ridge:cv_alpha=\", cv_alpha )\n",
    "\n",
    "    #### alpha_min\n",
    "    ridge_model_min = Ridge(alpha = cv_alpha)\n",
    "    ridge_model_min.fit(X_train, Y_train)\n",
    "    rmse = mean_squared_error(Y_test, ridge_model_min.predict(X_test))\n",
    "\n",
    "    return sqrt(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W9qtwZYbplFt"
   },
   "outputs": [],
   "source": [
    "def ridge_lasso(X_train,X_test,Y_train,Y_test):\n",
    "\n",
    "    # Get best alpha via lassoCV\n",
    "    lasso_alphas = np.logspace(-10, 10, 100)\n",
    "    lassocv = LassoCV(alphas = lasso_alphas, cv = 10)\n",
    "    lassocv.fit(X_train, Y_train)\n",
    "\n",
    "    cv_alpha = lassocv.alpha_\n",
    "    print(\"ridge_lasso:cv_alpha=\", cv_alpha )\n",
    "    \n",
    "    # fit lasso with best alpha\n",
    "    lasso_model_min = Lasso(alpha = lassocv.alpha_, max_iter=10000)\n",
    "    lasso_model_min.fit(X_train, Y_train)\n",
    "\n",
    "    # refit ridge with lasso alpha and coefficients\n",
    "    nonzero_indices = np.where(lasso_model_min.coef_ != 0)[0]\n",
    "    ridge_model = Ridge(alpha = lassocv.alpha_)\n",
    "\n",
    "    ridge_model.fit(X_train[:, nonzero_indices], Y_train)\n",
    "    Ridge_mse_err = mean_squared_error(Y_test, ridge_model.predict(X_test[:, nonzero_indices]))\n",
    "\n",
    "    return sqrt(Ridge_mse_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_lasso_v2(X_train,X_test,Y_train,Y_test):\n",
    "\n",
    "    # Get best alpha via lassoCV\n",
    "    lasso_alphas = np.logspace(-10, 10, 100)\n",
    "    lassocv = LassoCV(alphas = lasso_alphas, cv = 10)\n",
    "    lassocv.fit(X_train, Y_train)\n",
    "\n",
    "    cv_alpha = lassocv.alpha_\n",
    "    print(\"ridge_lasso:cv_alpha=\", cv_alpha )\n",
    "    \n",
    "    # fit lasso with best alpha\n",
    "    lasso_model_min = Lasso(alpha = lassocv.alpha_, max_iter=10000)\n",
    "    lasso_model_min.fit(X_train, Y_train)\n",
    "\n",
    "    # refit ridge with lasso alpha and coefficients\n",
    "    nonzero_indices = np.where(lasso_model_min.coef_ != 0)[0]\n",
    "    X_train = X_train[:, nonzero_indices]\n",
    "    X_test = X_test[:, nonzero_indices]\n",
    "    \n",
    "    Ridge_mse_err = ridge(X_train,X_test,Y_train,Y_test)\n",
    "\n",
    "    return Ridge_mse_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SmoKfZtYY-y6"
   },
   "outputs": [],
   "source": [
    "def tree_model(X_train,X_test,Y_train,Y_test):\n",
    "\n",
    "    tree_regressor = GradientBoostingRegressor(\n",
    "    learning_rate=0.02, n_estimators=1000, subsample=0.5,max_depth=6)\n",
    "    tree_regressor.fit(X_train, Y_train)\n",
    "    tree_mse_err = mean_squared_error(Y_test, tree_regressor.predict(X_test))\n",
    "\n",
    "    return sqrt(tree_mse_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oztGCr-tX514",
    "outputId": "bf9369e7-fd8c-4b51-8863-4f68ea78e1bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                              | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 1:  0.12278497543738219\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 1:  0.12188825761986359\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 52.14008287999674\n",
      "ridge_lasso_rmse for folder 1:  0.1233148835652027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████▊                                                                                                          | 1/10 [00:46<06:57, 46.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 1:  0.11329311211909458\n",
      "Elapsed: 46.2949 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 2:  0.11757350222549937\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 2:  0.12152092464215274\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 210.49041445120218\n",
      "ridge_lasso_rmse for folder 2:  0.12011658577585196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████▌                                                                                              | 2/10 [01:29<05:55, 44.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 2:  0.11862266702048072\n",
      "Elapsed: 43.0662 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 3:  0.12437825475953741\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 3:  0.12376382443583703\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 132.19411484660287\n",
      "ridge_lasso_rmse for folder 3:  0.12471873669106365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████████████████▍                                                                                  | 3/10 [02:12<05:07, 43.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 3:  0.11117345237651846\n",
      "Elapsed: 43.2059 seconds\n",
      "lasso:cv_alpha= 0.001873817422860383\n",
      "lasso_rmse for folder 4:  0.12600628742945358\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 4:  0.12368339680808899\n",
      "ridge_lasso:cv_alpha= 0.001873817422860383\n",
      "ridge:cv_alpha= 83.02175681319736\n",
      "ridge_lasso_rmse for folder 4:  0.122357842006332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████████████████████▏                                                                      | 4/10 [03:11<04:58, 49.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 4:  0.11387815013495914\n",
      "Elapsed: 58.5556 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 5:  0.1129720728903483\n",
      "ridge:cv_alpha= 533.6699231206302\n",
      "ridge_rmse for folder 5:  0.11586671793772053\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 83.02175681319736\n",
      "ridge_lasso_rmse for folder 5:  0.11704117716929661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████                                                           | 5/10 [03:55<03:59, 47.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 5:  0.10587670386539665\n",
      "Elapsed: 44.6694 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 6:  0.13257142944871575\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 6:  0.13534479534472071\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 52.14008287999674\n",
      "ridge_lasso_rmse for folder 6:  0.1314133032991812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████████████████████████▊                                               | 6/10 [04:38<03:04, 46.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 6:  0.12525391266524674\n",
      "Elapsed: 42.566 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 7:  0.12737373524128653\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 7:  0.12864437848274576\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 132.19411484660287\n",
      "ridge_lasso_rmse for folder 7:  0.1251325984481344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████▌                                   | 7/10 [05:52<02:45, 55.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 7:  0.1314626980630854\n",
      "Elapsed: 73.4947 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 8:  0.12225806767408731\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 8:  0.12373076152280266\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 132.19411484660287\n",
      "ridge_lasso_rmse for folder 8:  0.12096993592487626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████▍                       | 8/10 [06:39<01:45, 52.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 8:  0.12327936753554727\n",
      "Elapsed: 47.4785 seconds\n",
      "lasso:cv_alpha= 0.001873817422860383\n",
      "lasso_rmse for folder 9:  0.12988753578044188\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 9:  0.1332115659339513\n",
      "ridge_lasso:cv_alpha= 0.001873817422860383\n",
      "ridge:cv_alpha= 132.19411484660287\n",
      "ridge_lasso_rmse for folder 9:  0.13272381916800538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 9/10 [07:24<00:50, 50.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 9:  0.12939535683657677\n",
      "Elapsed: 44.7372 seconds\n",
      "lasso:cv_alpha= 0.0029836472402833404\n",
      "lasso_rmse for folder 10:  0.12400692710966692\n",
      "ridge:cv_alpha= 335.1602650938834\n",
      "ridge_rmse for folder 10:  0.1287548723379931\n",
      "ridge_lasso:cv_alpha= 0.0029836472402833404\n",
      "ridge:cv_alpha= 83.02175681319736\n",
      "ridge_lasso_rmse for folder 10:  0.12599510933546154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:11<00:00, 49.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_rmse for folder 10:  0.12000227755126956\n",
      "Elapsed: 46.6759 seconds\n",
      "CPU times: user 36min 43s, sys: 17min 5s, total: 53min 48s\n",
      "Wall time: 8min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    random.seed(4844)\n",
    "\n",
    "    dataset = tqdm(range (10))\n",
    "    #dataset = tqdm(np.array([2]))\n",
    "    for i in dataset:\n",
    "        index = i+1\n",
    "        \n",
    "        x_train_path = 'proj1/fold{}/train.csv'.format(index)\n",
    "        x_test_path = 'proj1/fold{}/test.csv'.format(index)\n",
    "        y_test_path = 'proj1/fold{}/test_y.csv'.format(index)\n",
    "\n",
    "        x_train_set = pd.read_csv(x_train_path)\n",
    "        x_test_set = pd.read_csv(x_test_path)\n",
    "        y_test_set = pd.read_csv(y_test_path)\n",
    "        y_test_set = np.log(y_test_set[\"Sale_Price\"])\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # linear model\n",
    "        X_train_final, y_train, variables_to_remove, medians_dict,winsorized_max,encoder, columns_to_encode, scaler = linear_trainset_preprocessing(x_train_set)\n",
    "        X_test_final = linear_testset_preprocessing(x_test_set,variables_to_remove,medians_dict, winsorized_max, encoder, columns_to_encode, scaler)\n",
    "\n",
    "        \"\"\"\n",
    "        lasso_rmse = lasso(X_train_final,X_test_final,y_train,y_test_set)\n",
    "\n",
    "        print (\"lasso_rmse for folder {}: \".format(index), lasso_rmse)\n",
    "        \n",
    "        ridge_lasso_rmse = ridge_lasso(X_train_final,X_test_final,y_train,y_test_set)\n",
    "\n",
    "        print (\"ridge_lasso_rmse for folder {}: \".format(index), ridge_lasso_rmse)\n",
    "        \"\"\"\n",
    "        \n",
    "        lasso_rmse = lasso(X_train_final,X_test_final,y_train,y_test_set)\n",
    "\n",
    "        print (\"lasso_rmse for folder {}: \".format(index), lasso_rmse)\n",
    "\n",
    "        ridge_rmse = ridge(X_train_final,X_test_final,y_train,y_test_set)\n",
    "\n",
    "        print (\"ridge_rmse for folder {}: \".format(index), ridge_rmse)\n",
    "        \n",
    "        ridge_lasso_rmse = ridge_lasso_v2(X_train_final,X_test_final,y_train,y_test_set)\n",
    "\n",
    "        print (\"ridge_lasso_rmse for folder {}: \".format(index), ridge_lasso_rmse)\n",
    "        \n",
    "\n",
    "        # tree model\n",
    "        x_train_final, y_train, medians_dict,encoder, columns_to_encode = tree_trainset_preprocessing(x_train_set)\n",
    "        X_test_final = tree_testset_preprocessing(x_test_set,medians_dict, encoder, columns_to_encode)\n",
    "\n",
    "        tree_rmse = tree_model(x_train_final,X_test_final,y_train,y_test_set)\n",
    "        print (\"tree_rmse for folder {}: \".format(index), tree_rmse)\n",
    "        \n",
    "        print(\"Elapsed: {} seconds\".format(round(time.time() - start_time, 4)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "    dataset = (range (10))\n",
    "    #dataset = tqdm(np.array([2]))\n",
    "    for i in dataset:\n",
    "        index = i+1\n",
    "        \n",
    "        x_train_path = 'proj1/fold{}/train.csv'.format(index)\n",
    "        x_test_path = 'proj1/fold{}/test.csv'.format(index)\n",
    "        #y_test_path = 'proj1/fold{}/test_y.csv'.format(index)\n",
    "\n",
    "        x_train_set = pd.read_csv(x_train_path)\n",
    "        x_test_set = pd.read_csv(x_test_path)\n",
    "        #y_test_set = pd.read_csv(y_test_path)\n",
    "        #y_test_set = np.log(y_test_set[\"Sale_Price\"])\n",
    "        \n",
    "        print(x_train_set.select_dtypes(include=['object']).isnull().any().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
